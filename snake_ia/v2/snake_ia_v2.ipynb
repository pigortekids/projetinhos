{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snake_ia_v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhzA3ABqyw_T",
        "colab_type": "text"
      },
      "source": [
        "##Esse notebook tem o intuito de criar uma inteligência artificial que joga snake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6Io6pY6zIwj",
        "colab_type": "text"
      },
      "source": [
        "###Conexão com o Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEp5Q8Xo_ben",
        "colab_type": "code",
        "outputId": "f9bc71b9-7dd1-4964-fccf-d131181966fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "caminho_drive = '/content/drive/My Drive/colab/snake/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZOFvAIVz0M-",
        "colab_type": "text"
      },
      "source": [
        "###Instalação das bibliotecas faltanes do Google Colab para rodar o código"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KbZ0y9R_7ko",
        "colab_type": "code",
        "outputId": "dd2f5323-4f14-490b-ae27-d6a8a718ae3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "source": [
        "!pip install keras-rl2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-rl2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/34/94ffeab44eef43e22a01d82aa0ca062a97392c2c2415ba8b210e72053285/keras_rl2-1.0.4-py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 40kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from keras-rl2) (2.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (3.2.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.18.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (0.34.2)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (2.2.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (2.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.28.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (0.9.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->keras-rl2) (1.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (1.6.0.post3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (3.2.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (2020.4.5.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->keras-rl2) (3.1.0)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFELLPe1zbac",
        "colab_type": "text"
      },
      "source": [
        "###Importação das bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REbl_5nc_-YE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import GreedyQPolicy, EpsGreedyQPolicy, LinearAnnealedPolicy\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g-isnczzhvA",
        "colab_type": "text"
      },
      "source": [
        "###Criação do modelo a ser utilizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0f9Xv6VAA7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cria_modelo(n_acoes, input_shape, porc_dropout):\n",
        "\n",
        "    rna = models.Sequential()\n",
        "    rna.add(layers.Flatten(input_shape=input_shape))\n",
        "\n",
        "    rna.add(layers.Dense(256,activation='relu', kernel_constraint=max_norm(3)))\n",
        "    rna.add(layers.Dropout(porc_dropout))\n",
        "\n",
        "    rna.add(layers.Dense(128,activation='relu', kernel_constraint=max_norm(3)))\n",
        "    rna.add(layers.Dropout(porc_dropout))\n",
        "\n",
        "    rna.add(layers.Dense(64,activation='relu', kernel_constraint=max_norm(3)))\n",
        "    rna.add(layers.Dropout(porc_dropout))\n",
        "\n",
        "    rna.add(layers.Dense(32,activation='relu', kernel_constraint=max_norm(3)))\n",
        "    rna.add(layers.Dropout(porc_dropout))\n",
        "\n",
        "    rna.add(layers.Dense(n_acoes, activation='softmax'))\n",
        "\n",
        "    #rna.compile(optimizer='sgd', loss='mse')\n",
        "    #rna.compile(optimizer='sgd', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "    return rna"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zzd2ROozlr6",
        "colab_type": "text"
      },
      "source": [
        "###Criação do ambiente customizado para o jogo com padrão de ambiente da OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO2pPClNAMfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SnakeEnv(gym.Env):\n",
        "    def __init__(self, janela_aprendizado):\n",
        "        self.n_acoes = 3\n",
        "        self.action_space = spaces.Discrete(self.n_acoes)\n",
        "        self.observation_space = spaces.Box( low=-1 , high=1 , shape=(janela_aprendizado,) + (7, 7) )\n",
        "        self.campo = None\n",
        "        self.qnt_linhas = None\n",
        "        self.qnt_colunas = None\n",
        "        self.posicoes_cobra = None\n",
        "        self.direcao_cobra = None\n",
        "        self.desconto_por_casa = -0.001\n",
        "        self.reset()\n",
        "\n",
        "    def observacao(self):\n",
        "        obs = []\n",
        "        for i in range( len(self.campo[0]) ):\n",
        "            obs.append( self.campo[0][i] )\n",
        "        return obs\n",
        "\n",
        "    def step(self, acao):\n",
        "        \n",
        "        recompensa = None\n",
        "        acabou = False\n",
        "        regret = 0\n",
        "\n",
        "        posicao_cabeca_x = self.posicoes_cobra[0][0]\n",
        "        posicao_cabeca_y = self.posicoes_cobra[0][1]\n",
        "\n",
        "        if acao == 1: #gira pra direita\n",
        "            self.direcao_cobra += 1\n",
        "            if self.direcao_cobra == 3:\n",
        "                direcao_cobra = 0\n",
        "        elif acao == 2: #gira pra direita\n",
        "            self.direcao_cobra -= 1\n",
        "            if self.direcao_cobra == -1:\n",
        "                direcao_cobra = 3\n",
        "        \n",
        "        if self.direcao_cobra == 0: #cima\n",
        "            posicao_cabeca_y += -1\n",
        "        elif self.direcao_cobra == 1: #direita\n",
        "            posicao_cabeca_x += 1\n",
        "        elif self.direcao_cobra == 2: #baixo\n",
        "            posicao_cabeca_y += 1\n",
        "        elif self.direcao_cobra == 3: #esquerda\n",
        "            posicao_cabeca_x += -1\n",
        "\n",
        "        recompensa = self.campo[0][ posicao_cabeca_y ][ posicao_cabeca_x ]\n",
        "\n",
        "        if recompensa == -1:\n",
        "            acabou = True\n",
        "        else:\n",
        "            self.posicoes_cobra.insert(0, [ posicao_cabeca_x, posicao_cabeca_y ])\n",
        "            self.campo[0][posicao_cabeca_y][posicao_cabeca_x] = 0\n",
        "\n",
        "            if recompensa == 1:\n",
        "                self.gera_maca()\n",
        "                self.campo[0][ self.posicoes_cobra[1][1] ][ self.posicoes_cobra[1][0] ] = -1\n",
        "            else:\n",
        "                self.campo[0][ self.posicoes_cobra[-1][1] ][ self.posicoes_cobra[-1][0] ] = self.desconto_por_casa\n",
        "                self.posicoes_cobra.pop()\n",
        "                self.campo[0][ self.posicoes_cobra[1][1] ][ self.posicoes_cobra[1][0] ] = -1\n",
        "\n",
        "        return self.observacao(), recompensa, acabou, {'regret':regret}\n",
        "\n",
        "    def gera_maca(self):\n",
        "        linha = 0\n",
        "        coluna = 0\n",
        "        while self.campo[0][linha][coluna] != self.desconto_por_casa:\n",
        "            linha = np.random.choice( self.qnt_linhas )\n",
        "            coluna = np.random.choice( self.qnt_colunas )\n",
        "        self.campo[0][linha][coluna] = 1\n",
        "\n",
        "    def reset(self):\n",
        "        self.campo = np.full( self.observation_space.shape, self.desconto_por_casa )\n",
        "        self.qnt_linhas = len(self.campo[0][0])\n",
        "        self.qnt_colunas = len(self.campo[0])\n",
        "        self.campo[0][0] = -1\n",
        "        self.campo[0][-1] = -1\n",
        "        for i in range(len(self.campo[0])):\n",
        "            self.campo[0][i][0] = -1\n",
        "            self.campo[0][i][-1] = -1\n",
        "        self.posicoes_cobra = []\n",
        "        self.posicoes_cobra.append( [int(self.qnt_linhas / 2), int(self.qnt_colunas / 2)] )\n",
        "        self.posicoes_cobra.append( [self.posicoes_cobra[0][0], self.posicoes_cobra[0][1] + 1] )\n",
        "        self.campo[0][ self.posicoes_cobra[0][1] ][ self.posicoes_cobra[0][0] ] = 0\n",
        "        self.campo[0][ self.posicoes_cobra[-1][1] ][ self.posicoes_cobra[-1][0] ] = -1\n",
        "        self.direcao_cobra = 0\n",
        "        self.gera_maca()\n",
        "        return self.observacao()\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        print()\n",
        "        for array in self.campo:\n",
        "            print(array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx70y9w-z7yJ",
        "colab_type": "text"
      },
      "source": [
        "###Definição das principais variáveis que serão utilizadas ao longo do código"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MCOE-THAOLE",
        "colab_type": "code",
        "outputId": "249fecc5-bd59-4bb8-d82c-af5f106db020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "np.random.seed(15)\n",
        "\n",
        "janela_aprendizado = 1 #quantas linhas da memoria vai pegar pra treinar o modelo por vez\n",
        "ambiente = SnakeEnv( janela_aprendizado ) #cria o ambiente para o jogo\n",
        "n_acoes = ambiente.n_acoes #define o numero de saidas da rede\n",
        "input_shape = ambiente.observation_space.shape\n",
        "batch_size = 32\n",
        "\n",
        "memoria = SequentialMemory(limit=50000, window_length=janela_aprendizado)\n",
        "porc_drop_out = 0.2\n",
        "modelo = cria_modelo( n_acoes, input_shape, porc_drop_out )\n",
        "metricas = ['accuracy']\n",
        "otimizador = optimizers.Adam()\n",
        "\n",
        "n_steps = []\n",
        "n_steps.append( 1000000 )\n",
        "n_steps.append( 400000 )\n",
        "n_steps.append( 400000 )\n",
        "n_steps.append( 500000 )\n",
        "n_steps_aquecimento = 1000\n",
        "n_max_steps_por_episodio = []\n",
        "n_max_steps_por_episodio.append( 100 )\n",
        "n_max_steps_por_episodio.append( 100 )\n",
        "n_max_steps_por_episodio.append( 100 )\n",
        "n_max_steps_por_episodio.append( 100 )\n",
        "\n",
        "politicas = []\n",
        "politicas.append( LinearAnnealedPolicy( inner_policy=EpsGreedyQPolicy(), attr='eps', value_max=1.0, value_min=0.2, nb_steps=n_steps[0], value_test=0 )  )\n",
        "politicas.append( EpsGreedyQPolicy( 0.2 ) )\n",
        "politicas.append( LinearAnnealedPolicy( inner_policy=EpsGreedyQPolicy(), attr='eps', value_max=0.2, value_min=0, nb_steps=n_steps[0], value_test=0 )  )\n",
        "politicas.append( GreedyQPolicy() )\n",
        "\n",
        "agora = str( datetime.now() - timedelta(hours = 3) ).replace(' ', '_')[:19] #horario de brasilia UTC-3\n",
        "caminho_export = '{0}{1}_'.format( caminho_drive, agora )\n",
        "arquivo_parametros = open( '{0}parametros.txt'.format( caminho_export ), 'w+' )\n",
        "arquivo_parametros.write( 'input shape = {}\\n\\n'.format(input_shape) )\n",
        "arquivo_parametros.write( 'desconto por casa = {}\\n\\n'.format(ambiente.desconto_por_casa) )\n",
        "arquivo_parametros.write( 'batch size = {}\\n\\n'.format(batch_size) )\n",
        "arquivo_parametros.write( 'modelo =\\n'.format() )\n",
        "with redirect_stdout(arquivo_parametros):\n",
        "    modelo.summary()\n",
        "arquivo_parametros.write( '\\nmetricas = {}\\n\\n'.format(metricas) )\n",
        "arquivo_parametros.write( 'numero de steps = {}\\n\\n'.format(n_steps) )\n",
        "arquivo_parametros.write( 'numero de steps de aquecimento = {}\\n\\n'.format(n_steps_aquecimento) )\n",
        "arquivo_parametros.write( 'numero maximo de steps por episodio = {}\\n\\n'.format(n_max_steps_por_episodio) )\n",
        "arquivo_parametros.write( 'politicas =' )\n",
        "for politica in politicas:\n",
        "    arquivo_parametros.write( '\\r{} {}'.format(politica, politica.__dict__) )\n",
        "arquivo_parametros.write( '\\n\\notimizador = {} {}\\n'.format(otimizador, otimizador.__dict__) )\n",
        "arquivo_parametros.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYC5-Abn0Bws",
        "colab_type": "text"
      },
      "source": [
        "###Treino do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU-pkJdGbHUU",
        "colab_type": "code",
        "outputId": "d76ed134-4ecb-4acd-bdbe-dc1137e3c92d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "resultados_treino = []\n",
        "callbacks_treino = []\n",
        "for etapa in range( len(n_steps) ):\n",
        "    callbacks_treino_etapa = []\n",
        "    callbacks_treino_etapa.append( FileLogger( 'log.log' ) )\n",
        "    callbacks_treino_etapa.append( FileLogger( '{0}log.log'.format( caminho_export ) ) )\n",
        "    callbacks_treino_etapa.append( LambdaCallback( on_batch_end=lambda batch,logs: resultados_treino.append( {'etapa':etapa, 'logs':logs} ) ) )\n",
        "    intervalo_modelo = int( n_steps[ etapa ] / 5 )\n",
        "    callbacks_treino_etapa.append( ModelIntervalCheckpoint( '{0}dqn.h5f'.format( caminho_export ) , interval=intervalo_modelo ) )\n",
        "    callbacks_treino.append( callbacks_treino_etapa )\n",
        "\n",
        "for etapa in range( len(n_steps) ):\n",
        "\n",
        "    agente = DQNAgent( model=modelo, policy=politicas[etapa], nb_actions=n_acoes, memory=memoria, enable_double_dqn=True, test_policy=GreedyQPolicy(), nb_steps_warmup=n_steps_aquecimento, batch_size=batch_size )\n",
        "    agente.compile( optimizer=otimizador, metrics=metricas )\n",
        "    if etapa > 0:\n",
        "        agente.load_weights( 'dqn.h5f' )\n",
        "    #else:\n",
        "    #    agente.load_weights( '{}2020-05-06_18:13:21.724267_dqn.h5f'.format( caminho_drive ) )\n",
        "\n",
        "    intervalo_log = int( n_steps[ etapa ] / 5 )\n",
        "    agente.fit( env=ambiente, nb_steps=n_steps[etapa], visualize=False, verbose=1, callbacks=callbacks_treino[etapa], log_interval=intervalo_log, nb_max_episode_steps=n_max_steps_por_episodio[etapa] )\n",
        "    print()\n",
        "\n",
        "    agente.save_weights( 'dqn.h5f', overwrite=True )\n",
        "    agente.save_weights( '{0}dqn.h5f'.format( caminho_export ), overwrite=True )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 1000000 steps ...\n",
            "Interval 1 (0 steps performed)\n",
            "200000/200000 [==============================] - 3312s 17ms/step - reward: -0.2699\n",
            "60423 episodes - episode_reward: -0.894 [-1.024, 2.985] - loss: 0.249 - accuracy: 0.410 - mean_q: 0.531 - mean_eps: 0.920 - regret: 0.000\n",
            "\n",
            "Interval 2 (200000 steps performed)\n",
            " 18775/200000 [=>............................] - ETA: 49:08 - reward: -0.2458Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG53Hrke0E_9",
        "colab_type": "text"
      },
      "source": [
        "###Criação dos gráficos das métricas do treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzY-5qJAfsZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.style.use('seaborn')\n",
        "#nm_metricas = ['recompensa', 'regret', 'loss', 'accuracy', 'mean_q', 'mean_eps']\n",
        "#metrica_max = [True, True, False, True, False, False]\n",
        "nm_metricas = ['recompensa', 'loss', 'accuracy', 'mean_q', 'mean_eps']\n",
        "metrica_max = [True, False, True, False, False]\n",
        "divisores = [100, 1000] #quantidade de episodios a dividir a media\n",
        "etapas = [d['etapa'] for d in resultados_treino]\n",
        "result = [d['logs'] for d in resultados_treino]\n",
        "n_resultados = len(result)\n",
        "tipo = 'treino_full'\n",
        "pular_n_steps = n_steps_aquecimento\n",
        "fig_size_x = 20\n",
        "fig_size_y = len(nm_metricas) * 6\n",
        "\n",
        "fig, axs = plt.subplots(len(nm_metricas), len(divisores), gridspec_kw={'hspace': 0.4, 'wspace': 0.2}, figsize=( fig_size_x , fig_size_y ))\n",
        "for metrica_i in range(len(nm_metricas)):\n",
        "\n",
        "    nm_metrica = nm_metricas[metrica_i]\n",
        "    if len(divisores) == 1:\n",
        "        axs[metrica_i].set(ylabel=nm_metrica)\n",
        "    else:\n",
        "        axs[metrica_i][0].set(ylabel=nm_metrica)\n",
        "    grafico = 0\n",
        "\n",
        "    for divisor in divisores:\n",
        "\n",
        "        axes = None\n",
        "        if len(divisores) == 1:\n",
        "            axes = axs[metrica_i]\n",
        "        else:\n",
        "            axes = axs[metrica_i][grafico]\n",
        "        grafico = 0\n",
        "        axes.set(title='Media do(a) {} a cada {} episodios'.format(nm_metrica, divisor))\n",
        "\n",
        "        hist_metricas = []\n",
        "        metricas_media = []\n",
        "        metricas_ref = []\n",
        "\n",
        "        # [ posicao em x do maior ponto na media , posicao y do maior ponto na media , maior ponto ]\n",
        "        max_metrica_media = [None, None]\n",
        "        min_metrica_media = [None, None]\n",
        "\n",
        "        for i in range(0, n_resultados):\n",
        "            if not math.isnan( result[i]['metrics'][0] ): #tira os steps de aquecimento\n",
        "                if metrica_i == 0: #recompensa\n",
        "                    metricas_ref.append( result[i]['reward'] )\n",
        "                #elif metrica_i == 1: #regret\n",
        "                #    metricas_ref.append( result[i]['info']['regret'] )\n",
        "                else: #outras metricas\n",
        "                    compara_metrica = metrica_i - 1\n",
        "                    if compara_metrica == len(result[i]['metrics']): #se for o epsilon\n",
        "                        if type(politicas[etapas[i]]) == type(EpsGreedyQPolicy()):\n",
        "                            metricas_ref.append( politicas[etapas[i]].eps )\n",
        "                        elif type(politicas[etapas[i]]) == type(GreedyQPolicy()):\n",
        "                            metricas_ref.append( 0 )\n",
        "                    else:\n",
        "                        metricas_ref.append( result[i]['metrics'][compara_metrica] )\n",
        "\n",
        "            if i > 0 and result[i]['episode'] != result[i-1]['episode'] and len(metricas_ref) > 0:\n",
        "                hist_metricas.append( sum(metricas_ref) / len(metricas_ref) )\n",
        "                metricas_ref = []\n",
        "\n",
        "            if len(hist_metricas) % divisor == 0 and len(hist_metricas) > 0:\n",
        "                metricas_media.append( sum(hist_metricas[-divisor:]) / divisor )\n",
        "                hist_metricas = []\n",
        "                #pega maximos e minimos\n",
        "                if max_metrica_media[1] == None or metricas_media[-1] >= max_metrica_media[1]:\n",
        "                    max_metrica_media[0] = len(metricas_media)\n",
        "                    max_metrica_media[1] = metricas_media[-1]\n",
        "                if min_metrica_media[1] == None or metricas_media[-1] <= min_metrica_media[1]:\n",
        "                    min_metrica_media[0] = len(metricas_media)\n",
        "                    min_metrica_media[1] = metricas_media[-1]\n",
        "        \n",
        "\n",
        "        #plota grafico\n",
        "        n_steps_media_total = len(metricas_media)\n",
        "        x_plot = np.arange(n_steps_media_total)\n",
        "        axes.set(xlabel='episodio / {}'.format(divisor))\n",
        "        axes.plot(x_plot, metricas_media)\n",
        "\n",
        "        n_episodios_ant = 0\n",
        "        pular_n_episodes = 0\n",
        "        for i in range( len(n_steps) ):\n",
        "\n",
        "            n_episodios = 0\n",
        "            step_inicial = 0\n",
        "            step_final = 0\n",
        "            for j in range(i+1):\n",
        "                step_final += n_steps[j] - 1\n",
        "                n_episodios += result[step_final]['episode']\n",
        "                step_final += 1\n",
        "            for j in range(i):\n",
        "                step_inicial += n_steps[j] - 1\n",
        "            step_inicial += pular_n_steps\n",
        "\n",
        "            pular_n_episodes += result[step_inicial]['episode']\n",
        "            n_episodios -= pular_n_episodes\n",
        "\n",
        "            n_episodios_divisor = int(n_episodios / divisor)\n",
        "            n_episodios_ant_divisor = int(n_episodios_ant / divisor)\n",
        "\n",
        "            #linha de tendencia\n",
        "            z = np.polyfit( x_plot[ n_episodios_ant_divisor : n_episodios_divisor ], metricas_media[ n_episodios_ant_divisor : n_episodios_divisor ], 1 )\n",
        "            p = np.poly1d(z)\n",
        "            axes.plot( x_plot[ n_episodios_ant_divisor : n_episodios_divisor ], p(x_plot[ n_episodios_ant_divisor : n_episodios_divisor ]), c='#ff0000', ls=\"--\", linewidth=3, label='tendencia etapa {}'.format(i) )\n",
        "\n",
        "            if i < len(n_steps) - 1:\n",
        "                #linha de separacao de treinos\n",
        "                axes.axvline( x=n_episodios_divisor, c='#00ff00' , linewidth=1, label='divisor das etapas {} da {}'.format(i, i+1) )\n",
        "\n",
        "            n_episodios_ant = n_episodios\n",
        "        \n",
        "        #maximo e minimo\n",
        "        if metrica_max[metrica_i]:\n",
        "            #linha de maximo\n",
        "            anotacao_x_max = max_metrica_media[0]\n",
        "            if max_metrica_media[0] > n_steps_media_total / 2:\n",
        "                anotacao_x_max = n_steps_media_total * 0.9\n",
        "            anotacao_y_max = ((max_metrica_media[1] - min_metrica_media[1]) * 0.6) + min_metrica_media[1]\n",
        "            axes.axhline(max_metrica_media[1], c='#ff6600', ls='--', linewidth=2, label='maximo_1')\n",
        "            axes.annotate( 'max = {:.4f}'.format(max_metrica_media[1]), \n",
        "                                            xy=( max_metrica_media[0] , max_metrica_media[1] ),\n",
        "                                            xytext=( anotacao_x_max , anotacao_y_max ),\n",
        "                                            arrowprops=dict(facecolor='black', shrink=0.05) )\n",
        "        else:\n",
        "            #linha de minimo\n",
        "            anotacao_x_min = min_metrica_media[0]\n",
        "            if min_metrica_media[0] > n_steps_media_total / 2:\n",
        "                anotacao_x_min = n_steps_media_total * 0.9\n",
        "            anotacao_y_min = ((max_metrica_media[1] - min_metrica_media[1]) * 0.4) + min_metrica_media[1]\n",
        "            axes.axhline(min_metrica_media[1], c='#ff6600', ls='--', linewidth=2, label='minimo_1')\n",
        "            axes.annotate( 'min = {:.4f}'.format(min_metrica_media[1]),\n",
        "                                            xy=( min_metrica_media[0] , min_metrica_media[1] ),\n",
        "                                            xytext=( anotacao_x_min , anotacao_y_min ),\n",
        "                                            arrowprops=dict(facecolor='black', shrink=0.03) )\n",
        "        \n",
        "        grafico += 1\n",
        "\n",
        "fig.show()\n",
        "fig.savefig('result_{}.png'.format(tipo), bbox_inches='tight') #salva o grafico em uma foto\n",
        "fig.savefig('{0}result_{1}.png'.format( caminho_export, tipo ), bbox_inches='tight') #salva o grafico em uma foto"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jlF8yFL0Ru4",
        "colab_type": "text"
      },
      "source": [
        "###Teste do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZeuV5yvmZHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ambiente = SnakeEnv( 1 ) #cria o ambiente para o jogo\n",
        "\n",
        "agente = DQNAgent( model=modelo, policy=GreedyQPolicy(), nb_actions=n_acoes, memory=memoria, test_policy=GreedyQPolicy() )\n",
        "agente.compile(optimizers.Adam(), metrics=metricas)\n",
        "agente.load_weights('dqn.h5f')\n",
        "\n",
        "n_max_steps_por_episodio_test = 50\n",
        "\n",
        "resultados_teste = []\n",
        "callbacks_teste = []\n",
        "callbacks_teste.append( LambdaCallback( on_batch_end=lambda batch,logs: resultados_teste.append( logs ) ) )\n",
        "agente.test(ambiente, nb_episodes=10, verbose=1, visualize=False, callbacks=callbacks_teste, nb_max_episode_steps=n_max_steps_por_episodio_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UQw5ElK0TuN",
        "colab_type": "text"
      },
      "source": [
        "###Criação de um vídeo relativo ao teste do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7IwtVKwOUPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pinta_mais( x, y, tamanho, data, cor ):\n",
        "    for i in range(tamanho):\n",
        "        for j in range(tamanho):\n",
        "            data[tamanho * x + i][tamanho * y + j] = cor\n",
        "\n",
        "import cv2\n",
        "\n",
        "# initialize water image\n",
        "tamanho = 20\n",
        "tamanho_x = ambiente.observation_space.shape[1] * tamanho\n",
        "tamanho_y = ambiente.observation_space.shape[2] * tamanho\n",
        "water_depth = np.zeros((tamanho_y, tamanho_x), dtype=float)\n",
        "\n",
        "# initialize video writer\n",
        "cap = cv2.VideoCapture(0)\n",
        "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "fps = 3\n",
        "video_filename = '{0}test.mp4'.format( caminho_export )\n",
        "out = cv2.VideoWriter(video_filename, fourcc, fps, (tamanho_x, tamanho_y))\n",
        "contagem = 0\n",
        "\n",
        "for log in resultados_teste:\n",
        "    data = np.zeros( (tamanho_x, tamanho_y, 3), dtype=np.uint8 )\n",
        "    for i in range(int(tamanho_x / tamanho)):\n",
        "        for j in range(int(tamanho_y / tamanho)):\n",
        "            if log['observation'][j][i] == 1:\n",
        "                pinta_mais(i, j, tamanho, data, [0,0,255] ) #red\n",
        "            elif i == 0 or j == 0 or i == int(tamanho_x / tamanho) - 1 or j == int(tamanho_y / tamanho) - 1:\n",
        "                pinta_mais(i, j, tamanho, data, [255,0,0] ) #blue\n",
        "            elif log['observation'][j][i] == ambiente.desconto_por_casa:\n",
        "                pinta_mais(i, j, tamanho, data, [255,255,255] )\n",
        "            elif log['observation'][j][i] == 0:\n",
        "                pinta_mais(i, j, tamanho, data, [0,100,0] ) #green\n",
        "            else:\n",
        "                pinta_mais(i, j, tamanho, data, [0,255,0] ) #green\n",
        "            \n",
        "    if contagem > 0 and resultados_teste[contagem]['episode'] != resultados_teste[contagem-1]['episode']:\n",
        "        data.fill(0)\n",
        "        out.write(data)\n",
        "        out.write(data)\n",
        "    contagem += 1\n",
        "\n",
        "    out.write(data)\n",
        "\n",
        "# close out the video writer\n",
        "out.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9dOYIqTwu0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}